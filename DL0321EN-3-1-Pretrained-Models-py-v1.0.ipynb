{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "import skillsnetwork \n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 18:53:50.500761: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-26 18:53:50.506738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-26 18:53:50.506765: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item32'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a441c043d9144898306bf46fe9b126b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading concrete_data_week3.zip:   0%|          | 0/261482368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c7dc8c55bf48d3911ad4a2c7f75a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80037 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to '.'\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "await skillsnetwork.prepare(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item34'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item35'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 18:58:09.855537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-26 18:58:09.855613: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-26 18:58:09.855653: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyterlab-amirzon10): /proc/driver/nvidia/version does not exist\n",
      "2023-12-26 18:58:09.856287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "access the model's layers using the *layers* attribute of our model object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x7f877cea5ed0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f877ca40c10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f879ba5e0d0>,\n",
       " <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7f8794f03950>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f8800403610>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f878e755850>,\n",
       " <keras.layers.core.activation.Activation at 0x7f878e73dfd0>,\n",
       " <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7f879d542110>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7f879d4e0510>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f879d513c50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ceeca90>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ceec050>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ceea590>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cedf3d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f878f14d6d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ceda310>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce80fd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cedac50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cef70d0>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce90d10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce950d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce8b150>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8794eef790>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cea5250>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cea7790>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cea02d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ceb6250>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce9a650>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce3d510>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce41cd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce51110>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce4ead0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce4eb50>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce64990>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce64b10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce5b090>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce4e550>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce70210>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce70510>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce02410>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce0ec50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce11910>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce18310>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce02f50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cea0c90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce51c10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce52510>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f878e756190>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce4e8d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce095d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cea74d0>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce3d1d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce4e090>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce95cd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cef4c10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ceec350>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce4e5d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cea56d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce4e210>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce861d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ce34990>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce34c10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ceeaad0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce3bad0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cdc3d10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cdc3790>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdbe090>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cdd6890>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cdd66d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce2f490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f879d4e7210>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cdec350>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cdd3490>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce02690>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd7f310>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd7f8d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cde22d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd8f910>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd8fb90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdf0950>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cda2990>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cdc33d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd9ad90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdb3cd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cdb3110>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cda2650>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdd3b10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cdf64d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce242d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cda7ad0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ce2cbd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cdb3d90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f879d4e73d0>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce52fd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cdfe8d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd43610>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd43a50>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cdb9790>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd4ef10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd4e9d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd656d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdd6990>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd65a90>,\n",
       " <keras.layers.merging.add.Add at 0x7f877ce86990>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce24d90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd74790>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd68450>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd11490>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd0cb50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd05250>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd20450>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd20750>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd207d0>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cd31cd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd31f50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd31710>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd2aa10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ccce250>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ccc1c50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ccc6590>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ccd5290>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ccd5d10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ccd5bd0>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cceabd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cceae50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ccea5d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ccdab10>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd24b50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd2a090>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd3c090>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd0cb10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd74d10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd7ad50>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cd55bd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ce9a310>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd42050>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cd6a4d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cde5f10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ccf3dd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cdd6f50>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd424d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc8a410>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc8a590>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cd3c290>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cd11790>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc92a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ccafc50>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cca8fd0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877ccbb050>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877ccbb650>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ccb9b50>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdf0ad0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cd89750>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc9ee90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc55890>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cc55f90>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ccb5e90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc5af10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc65610>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cc65510>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc6c650>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f879ba59fd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cc715d0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc5a690>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc656d0>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cc011d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cc01fd0>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc6ca50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc9ebd0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cca1a90>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cc4fd90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc4fc90>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877ccafa10>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7f877cdd6590>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f877cc8fe10>,\n",
       " <keras.layers.merging.add.Add at 0x7f877cc476d0>,\n",
       " <keras.layers.core.activation.Activation at 0x7f877cdf67d0>,\n",
       " <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x7f877ce95ed0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "301/301 [==============================] - 3823s 13s/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.0079 - val_accuracy: 0.9984\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 3923s 13s/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0051 - val_accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
